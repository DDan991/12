{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:43:41.739463Z","iopub.status.busy":"2024-02-19T22:43:41.739089Z","iopub.status.idle":"2024-02-19T22:43:41.752019Z","shell.execute_reply":"2024-02-19T22:43:41.750920Z","shell.execute_reply.started":"2024-02-19T22:43:41.739431Z"},"trusted":true},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:43:43.876343Z","iopub.status.busy":"2024-02-19T22:43:43.875430Z","iopub.status.idle":"2024-02-19T22:43:57.051322Z","shell.execute_reply":"2024-02-19T22:43:57.050405Z","shell.execute_reply.started":"2024-02-19T22:43:43.876307Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.3.0.post0)\n","Requirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.24.4)\n","Requirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (21.3)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.1.2)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (0.10.1)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.0.3)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>17.1->torchmetrics) (3.1.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2023.12.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n"]}],"source":["!pip install torchmetrics"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:44:00.263356Z","iopub.status.busy":"2024-02-19T22:44:00.262465Z","iopub.status.idle":"2024-02-19T22:44:01.389536Z","shell.execute_reply":"2024-02-19T22:44:01.388675Z","shell.execute_reply.started":"2024-02-19T22:44:00.263321Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","import ssl\n","\n","try:\n","    _create_unverified_https_context = ssl._create_unverified_context\n","except AttributeError:\n","    pass\n","else:\n","    ssl._create_default_https_context = _create_unverified_https_context\n","\n","nltk.download('punkt')"]},{"cell_type":"markdown","metadata":{},"source":["Loading data files\n","=================="]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:44:04.021558Z","iopub.status.busy":"2024-02-19T22:44:04.021113Z","iopub.status.idle":"2024-02-19T22:44:09.769444Z","shell.execute_reply":"2024-02-19T22:44:09.768271Z","shell.execute_reply.started":"2024-02-19T22:44:04.021531Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-02-19 22:44:04--  http://www.manythings.org/anki/fra-eng.zip\n","Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n","Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 7833145 (7.5M) [application/zip]\n","Saving to: 'fra-eng.zip'\n","\n","fra-eng.zip         100%[===================>]   7.47M  6.14MB/s    in 1.2s    \n","\n","2024-02-19 22:44:06 (6.14 MB/s) - 'fra-eng.zip' saved [7833145/7833145]\n","\n","Archive:  fra-eng.zip\n","  inflating: _about.txt              \n","  inflating: fra.txt                 \n"]}],"source":["!wget http://www.manythings.org/anki/fra-eng.zip\n","!unzip -o fra-eng.zip\n","!mkdir data\n","!mv fra.txt data/eng-fra.txt"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:44:13.005479Z","iopub.status.busy":"2024-02-19T22:44:13.004570Z","iopub.status.idle":"2024-02-19T22:44:16.406843Z","shell.execute_reply":"2024-02-19T22:44:16.405853Z","shell.execute_reply.started":"2024-02-19T22:44:13.005444Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata\n","import string\n","import re\n","import random\n","SOS_token = 0\n","EOS_token = 1\n","\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n","        self.n_words = 2  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:44:20.162613Z","iopub.status.busy":"2024-02-19T22:44:20.161759Z","iopub.status.idle":"2024-02-19T22:44:20.168371Z","shell.execute_reply":"2024-02-19T22:44:20.167416Z","shell.execute_reply.started":"2024-02-19T22:44:20.162584Z"},"trusted":true},"outputs":[],"source":["# Turn a Unicode string to plain ASCII, thanks to\n","# http://stackoverflow.com/a/518232/2809427\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","\n","# Lowercase, trim, and remove non-letter characters\n","\n","\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","    return s"]},{"cell_type":"markdown","metadata":{},"source":["To read the data file we will split the file into lines, and then split\n","lines into pairs. The files are all English → Other Language, so if we\n","want to translate from Other Language → English I added the ``reverse``\n","flag to reverse the pairs."]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:44:32.163921Z","iopub.status.busy":"2024-02-19T22:44:32.163103Z","iopub.status.idle":"2024-02-19T22:44:32.170673Z","shell.execute_reply":"2024-02-19T22:44:32.169588Z","shell.execute_reply.started":"2024-02-19T22:44:32.163888Z"},"trusted":true},"outputs":[],"source":["def readLangs(lang1, lang2, reverse=False):\n","    print(\"Reading lines...\")\n","\n","    # Read the file and split into lines\n","    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n","        read().strip().split('\\n')\n","\n","    # Split every line into pairs and normalize\n","    pairs = [[normalizeString(s) for s in l.split('\\t')[:2]] for l in lines]\n","\n","    # Reverse pairs, make Lang instances\n","    if reverse:\n","        pairs = [list(reversed(p)) for p in pairs]\n","        input_lang = Lang(lang2)\n","        output_lang = Lang(lang1)\n","    else:\n","        input_lang = Lang(lang1)\n","        output_lang = Lang(lang2)\n","\n","    return input_lang, output_lang, pairs"]},{"cell_type":"markdown","metadata":{},"source":["Since there are a *lot* of example sentences and we want to train\n","something quickly, we'll trim the data set to only relatively short and\n","simple sentences. Here the maximum length is 15 words (that includes\n","ending punctuation) and we're filtering to sentences that translate to\n","the form \"I am\" or \"He is\" etc. (accounting for apostrophes replaced\n","earlier)."]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:44:34.669633Z","iopub.status.busy":"2024-02-19T22:44:34.669279Z","iopub.status.idle":"2024-02-19T22:44:34.676041Z","shell.execute_reply":"2024-02-19T22:44:34.675065Z","shell.execute_reply.started":"2024-02-19T22:44:34.669605Z"},"trusted":true},"outputs":[],"source":["MAX_LENGTH = 15\n","\n","eng_prefixes = (\n","    \"i am\", \"i m\",\n","    \"he is\", \"he s\",\n","    \"she is\", \"she s\",\n","    \"you are\", \"you re\",\n","    \"we are\", \"we re\",\n","    \"they are\", \"they re\"\n",")\n","\n","\n","def filterPair(p):\n","    return len(p[0].split(' ')) < MAX_LENGTH and \\\n","        len(p[1].split(' ')) < MAX_LENGTH and \\\n","        p[1].startswith(eng_prefixes)\n","\n","\n","def filterPairs(pairs):\n","    return [pair for pair in pairs if filterPair(pair)]"]},{"cell_type":"markdown","metadata":{},"source":["The full process for preparing the data is:\n","\n","-  Read text file and split into lines, split lines into pairs\n","-  Normalize text, filter by length and content\n","-  Make word lists from sentences in pairs"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:44:38.243286Z","iopub.status.busy":"2024-02-19T22:44:38.242582Z","iopub.status.idle":"2024-02-19T22:44:50.274671Z","shell.execute_reply":"2024-02-19T22:44:50.273836Z","shell.execute_reply.started":"2024-02-19T22:44:38.243254Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading lines...\n","Read 229803 sentence pairs\n","Trimmed to 22708 sentence pairs\n","Counting words...\n","Counted words:\n","fra 6986\n","eng 4611\n"]}],"source":["def prepareData(lang1, lang2, reverse=False):\n","    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n","    print(\"Read %s sentence pairs\" % len(pairs))\n","    pairs = filterPairs(pairs)\n","    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        input_lang.addSentence(pair[0])\n","        output_lang.addSentence(pair[1])\n","    print(\"Counted words:\")\n","    print(input_lang.name, input_lang.n_words)\n","    print(output_lang.name, output_lang.n_words)\n","    return input_lang, output_lang, pairs\n","\n","\n","input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n","#print(random.choice(pairs))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:44:53.619752Z","iopub.status.busy":"2024-02-19T22:44:53.619360Z","iopub.status.idle":"2024-02-19T22:44:53.652851Z","shell.execute_reply":"2024-02-19T22:44:53.652009Z","shell.execute_reply.started":"2024-02-19T22:44:53.619722Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X = [i[0] for i in pairs]\n","y = [i[1] for i in pairs]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n","\n","train_pairs = list(zip(X_train,y_train))\n","test_pairs = list(zip(X_test,y_test))"]},{"cell_type":"markdown","metadata":{},"source":["The Seq2Seq Model\n","================="]},{"cell_type":"markdown","metadata":{},"source":["The Encoder\n","-----------\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:44:58.476063Z","iopub.status.busy":"2024-02-19T22:44:58.474829Z","iopub.status.idle":"2024-02-19T22:44:58.485259Z","shell.execute_reply":"2024-02-19T22:44:58.484001Z","shell.execute_reply.started":"2024-02-19T22:44:58.476017Z"},"trusted":true},"outputs":[],"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        output = embedded\n","        output, hidden = self.gru(output, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"]},{"cell_type":"markdown","metadata":{},"source":["The Decoder\n","-----------\n","\n","The decoder is another RNN that takes the encoder output vector(s) and\n","outputs a sequence of words to create the translation.\n"]},{"cell_type":"markdown","metadata":{},"source":["Attention Decoder\n","^^^^^^^^^^^^^^^^^ (Example)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:45:04.821150Z","iopub.status.busy":"2024-02-19T22:45:04.820766Z","iopub.status.idle":"2024-02-19T22:45:04.832471Z","shell.execute_reply":"2024-02-19T22:45:04.831368Z","shell.execute_reply.started":"2024-02-19T22:45:04.821111Z"},"trusted":true},"outputs":[],"source":["class AttnDecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        attn_weights = F.softmax(\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs.unsqueeze(0))\n","\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"]},{"cell_type":"markdown","metadata":{},"source":["\n","\n","Training\n","========\n","\n","Preparing Training Data\n","-----------------------"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:45:07.511040Z","iopub.status.busy":"2024-02-19T22:45:07.510659Z","iopub.status.idle":"2024-02-19T22:45:07.517568Z","shell.execute_reply":"2024-02-19T22:45:07.516645Z","shell.execute_reply.started":"2024-02-19T22:45:07.511006Z"},"trusted":true},"outputs":[],"source":["def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","\n","def tensorFromSentence(lang, sentence):\n","    indexes = indexesFromSentence(lang, sentence)\n","    indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","\n","def tensorsFromPair(pair):\n","    input_tensor = tensorFromSentence(input_lang, pair[0])\n","    target_tensor = tensorFromSentence(output_lang, pair[1])\n","    return (input_tensor, target_tensor)"]},{"cell_type":"markdown","metadata":{},"source":["Training the Model\n","------------------"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:45:09.893635Z","iopub.status.busy":"2024-02-19T22:45:09.893247Z","iopub.status.idle":"2024-02-19T22:45:09.905122Z","shell.execute_reply":"2024-02-19T22:45:09.903983Z","shell.execute_reply.started":"2024-02-19T22:45:09.893602Z"},"trusted":true},"outputs":[],"source":["teacher_forcing_ratio = 0.5\n","\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","    encoder_hidden = encoder.initHidden()\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","    loss = 0\n","\n","    for ei in range(input_length):\n","        encoder_output, encoder_hidden = encoder(\n","            input_tensor[ei], encoder_hidden)\n","        encoder_outputs[ei] = encoder_output[0, 0]\n","\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","\n","    decoder_hidden = encoder_hidden\n","\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    if use_teacher_forcing:\n","        # Teacher forcing: Feed the target as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]  # Teacher forcing\n","\n","    else:\n","        # Without teacher forcing: use its own predictions as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","            loss += criterion(decoder_output, target_tensor[di])\n","            if decoder_input.item() == EOS_token:\n","                break\n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length"]},{"cell_type":"markdown","metadata":{},"source":["This is a helper function to print time elapsed and estimated time\n","remaining given the current time and progress %."]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:45:12.898487Z","iopub.status.busy":"2024-02-19T22:45:12.898137Z","iopub.status.idle":"2024-02-19T22:45:12.905220Z","shell.execute_reply":"2024-02-19T22:45:12.904034Z","shell.execute_reply.started":"2024-02-19T22:45:12.898461Z"},"trusted":true},"outputs":[],"source":["import time\n","import math\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"]},{"cell_type":"markdown","metadata":{},"source":["The whole training process looks like this:\n","\n","-  Start a timer\n","-  Initialize optimizers and criterion\n","-  Create set of training pairs\n","-  Start empty losses array for plotting\n","\n","Then we call ``train`` many times and occasionally print the progress (%\n","of examples, time so far, estimated time) and average loss.\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:45:15.402658Z","iopub.status.busy":"2024-02-19T22:45:15.401823Z","iopub.status.idle":"2024-02-19T22:45:15.412300Z","shell.execute_reply":"2024-02-19T22:45:15.411424Z","shell.execute_reply.started":"2024-02-19T22:45:15.402624Z"},"trusted":true},"outputs":[],"source":["def trainIters(encoder, decoder, epochs, print_every=1000, plot_every=100, learning_rate=0.01):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","\n","    criterion = nn.NLLLoss()\n","\n","    iter = 1\n","    n_iters = len(train_pairs) * epochs\n","\n","    for epoch in range(epochs):\n","        print(\"Epoch: %d/%d\" % (epoch, epochs))\n","        for training_pair in train_pairs:\n","            training_pair = tensorsFromPair(training_pair)\n","\n","            input_tensor = training_pair[0]\n","            target_tensor = training_pair[1]\n","\n","            loss = train(input_tensor, target_tensor, encoder,\n","                        decoder, encoder_optimizer, decoder_optimizer, criterion)\n","            print_loss_total += loss\n","            plot_loss_total += loss\n","\n","            if iter % print_every == 0:\n","                print_loss_avg = print_loss_total / print_every\n","                print_loss_total = 0\n","                print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n","                                            iter, iter / n_iters * 100, print_loss_avg))\n","\n","            if iter % plot_every == 0:\n","                plot_loss_avg = plot_loss_total / plot_every\n","                plot_losses.append(plot_loss_avg)\n","                plot_loss_total = 0\n","\n","            iter +=1\n","\n","    showPlot(plot_losses)"]},{"cell_type":"markdown","metadata":{},"source":["Plotting results\n","----------------\n","\n","Plotting is done with matplotlib, using the array of loss values\n","``plot_losses`` saved while training.\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:45:18.242483Z","iopub.status.busy":"2024-02-19T22:45:18.241840Z","iopub.status.idle":"2024-02-19T22:45:18.248507Z","shell.execute_reply":"2024-02-19T22:45:18.247496Z","shell.execute_reply.started":"2024-02-19T22:45:18.242449Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.switch_backend('agg')\n","import matplotlib.ticker as ticker\n","import numpy as np\n","\n","\n","def showPlot(points):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    # this locator puts ticks at regular intervals\n","    loc = ticker.MultipleLocator(base=0.2)\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)"]},{"cell_type":"markdown","metadata":{},"source":["Evaluation\n","==========\n","\n","Evaluation is mostly the same as training, but there are no targets so\n","we simply feed the decoder's predictions back to itself for each step.\n","Every time it predicts a word we add it to the output string, and if it\n","predicts the EOS token we stop there. We also store the decoder's\n","attention outputs for display later."]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:45:20.703579Z","iopub.status.busy":"2024-02-19T22:45:20.702819Z","iopub.status.idle":"2024-02-19T22:45:20.712233Z","shell.execute_reply":"2024-02-19T22:45:20.711290Z","shell.execute_reply.started":"2024-02-19T22:45:20.703544Z"},"trusted":true},"outputs":[],"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(input_lang, sentence)\n","        input_length = input_tensor.size()[0]\n","        encoder_hidden = encoder.initHidden()\n","\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n","                                                     encoder_hidden)\n","            encoder_outputs[ei] += encoder_output[0, 0]\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","\n","        decoded_words = []\n","\n","        for di in range(max_length):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words"]},{"cell_type":"markdown","metadata":{},"source":["We can evaluate random sentences from the training set and print out the\n","input, target, and output to make some subjective quality judgements:"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:45:23.452724Z","iopub.status.busy":"2024-02-19T22:45:23.452365Z","iopub.status.idle":"2024-02-19T22:45:23.460421Z","shell.execute_reply":"2024-02-19T22:45:23.459335Z","shell.execute_reply.started":"2024-02-19T22:45:23.452695Z"},"trusted":true},"outputs":[],"source":["def evaluateRandomly(encoder, decoder, n=10):\n","    for i in range(n):\n","        pair = random.choice(pairs)\n","        print('>', pair[0])\n","        print('=', pair[1])\n","        output_words = evaluate(encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words)\n","        print('<', output_sentence)\n","        print('')"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:45:27.049715Z","iopub.status.busy":"2024-02-19T22:45:27.049363Z","iopub.status.idle":"2024-02-19T22:45:31.182943Z","shell.execute_reply":"2024-02-19T22:45:31.182130Z","shell.execute_reply.started":"2024-02-19T22:45:27.049687Z"},"trusted":true},"outputs":[],"source":["from torchmetrics.text.rouge import ROUGEScore\n","from tqdm import tqdm\n","\n","rouge = ROUGEScore()\n","\n","def test(encoder, decoder, testing_pairs):\n","    input = []\n","    gt = []\n","    predict = []\n","    metric_score = {\n","        \"rouge1_fmeasure\":[],\n","        \"rouge1_precision\":[],\n","        \"rouge1_recall\":[],\n","        \"rouge2_fmeasure\":[],\n","        \"rouge2_precision\":[],\n","        \"rouge2_recall\":[]\n","    }\n","    from tqdm import tqdm\n","    for i in tqdm(range(len(testing_pairs))):\n","        pair = testing_pairs[i]\n","        output_words = evaluate(encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words)\n","\n","        input.append(pair[0])\n","        gt.append(pair[1])\n","        predict.append(output_sentence)\n","\n","        try:\n","            rs = rouge(output_sentence, pair[1])\n","        except:\n","            continue\n","        metric_score[\"rouge1_fmeasure\"].append(rs['rouge1_fmeasure'])\n","        metric_score[\"rouge1_precision\"].append(rs['rouge1_precision'])\n","        metric_score[\"rouge1_recall\"].append(rs['rouge1_recall'])\n","        metric_score[\"rouge2_fmeasure\"].append(rs['rouge2_fmeasure'])\n","        metric_score[\"rouge2_precision\"].append(rs['rouge2_precision'])\n","        metric_score[\"rouge2_recall\"].append(rs['rouge2_recall'])\n","\n","    metric_score[\"rouge1_fmeasure\"] = np.array(metric_score[\"rouge1_fmeasure\"]).mean()\n","    metric_score[\"rouge1_precision\"] = np.array(metric_score[\"rouge1_precision\"]).mean()\n","    metric_score[\"rouge1_recall\"] = np.array(metric_score[\"rouge1_recall\"]).mean()\n","    metric_score[\"rouge2_fmeasure\"] = np.array(metric_score[\"rouge2_fmeasure\"]).mean()\n","    metric_score[\"rouge2_precision\"] = np.array(metric_score[\"rouge2_precision\"]).mean()\n","    metric_score[\"rouge2_recall\"] = np.array(metric_score[\"rouge2_recall\"]).mean()\n","\n","    print(\"=== Evaluation score - Rouge score ===\")\n","    print(\"Rouge1 fmeasure:\\t\",metric_score[\"rouge1_fmeasure\"])\n","    print(\"Rouge1 precision:\\t\",metric_score[\"rouge1_precision\"])\n","    print(\"Rouge1 recall:  \\t\",metric_score[\"rouge1_recall\"])\n","    print(\"Rouge2 fmeasure:\\t\",metric_score[\"rouge2_fmeasure\"])\n","    print(\"Rouge2 precision:\\t\",metric_score[\"rouge2_precision\"])\n","    print(\"Rouge2 recall:  \\t\",metric_score[\"rouge2_recall\"])\n","    print(\"=====================================\")\n","    return input,gt,predict,metric_score"]},{"cell_type":"markdown","metadata":{},"source":["Training and Evaluating\n","=======================\n","\n","With all these helper functions in place (it looks like extra work, but\n","it makes it easier to run multiple experiments) we can actually\n","initialize a network and start training.\n","\n","Remember that the input sentences were heavily filtered. For this small\n","dataset we can use relatively small networks of 256 hidden nodes and a\n","single GRU layer. After about 40 minutes on a MacBook CPU we'll get some\n","reasonable results.\n","\n",".. Note::\n","   If you run this notebook you can train, interrupt the kernel,\n","   evaluate, and continue training later. Comment out the lines where the\n","   encoder and decoder are initialized and run ``trainIters`` again."]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T07:22:02.225015Z","iopub.status.busy":"2024-02-19T07:22:02.223966Z","iopub.status.idle":"2024-02-19T07:47:04.564828Z","shell.execute_reply":"2024-02-19T07:47:04.563812Z","shell.execute_reply.started":"2024-02-19T07:22:02.224975Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0/4\n","0m 17s (- 23m 49s) (1000 1%) 3.7981\n","0m 35s (- 23m 37s) (2000 2%) 3.3534\n","0m 53s (- 23m 17s) (3000 3%) 3.1568\n","1m 11s (- 23m 7s) (4000 4%) 3.0436\n","1m 29s (- 22m 52s) (5000 6%) 2.9308\n","1m 47s (- 22m 39s) (6000 7%) 2.8430\n","2m 5s (- 22m 21s) (7000 8%) 2.8518\n","2m 23s (- 22m 4s) (8000 9%) 2.7422\n","2m 42s (- 21m 50s) (9000 11%) 2.7138\n","3m 0s (- 21m 31s) (10000 12%) 2.6023\n","3m 18s (- 21m 14s) (11000 13%) 2.5893\n","3m 36s (- 20m 57s) (12000 14%) 2.6246\n","3m 54s (- 20m 39s) (13000 15%) 2.5064\n","4m 12s (- 20m 22s) (14000 17%) 2.4385\n","4m 30s (- 20m 4s) (15000 18%) 2.4244\n","4m 48s (- 19m 47s) (16000 19%) 2.4142\n","5m 7s (- 19m 29s) (17000 20%) 2.4000\n","5m 25s (- 19m 12s) (18000 22%) 2.3571\n","5m 43s (- 18m 55s) (19000 23%) 2.3802\n","6m 1s (- 18m 37s) (20000 24%) 2.2832\n","Epoch: 1/4\n","6m 20s (- 18m 20s) (21000 25%) 2.2259\n","6m 38s (- 18m 2s) (22000 26%) 2.1896\n","6m 56s (- 17m 45s) (23000 28%) 2.1512\n","7m 15s (- 17m 27s) (24000 29%) 2.1119\n","7m 33s (- 17m 9s) (25000 30%) 2.0959\n","7m 51s (- 16m 51s) (26000 31%) 2.0687\n","8m 10s (- 16m 33s) (27000 33%) 2.0506\n","8m 28s (- 16m 16s) (28000 34%) 2.0722\n","8m 46s (- 15m 58s) (29000 35%) 1.9994\n","9m 5s (- 15m 40s) (30000 36%) 2.0265\n","9m 23s (- 15m 22s) (31000 37%) 1.9459\n","9m 41s (- 15m 4s) (32000 39%) 1.9874\n","10m 0s (- 14m 46s) (33000 40%) 1.9654\n","10m 18s (- 14m 28s) (34000 41%) 1.9193\n","10m 37s (- 14m 11s) (35000 42%) 1.9018\n","10m 55s (- 13m 52s) (36000 44%) 1.9294\n","11m 13s (- 13m 34s) (37000 45%) 1.8729\n","11m 32s (- 13m 17s) (38000 46%) 1.8588\n","11m 50s (- 12m 59s) (39000 47%) 1.9087\n","12m 9s (- 12m 41s) (40000 48%) 1.8106\n","Epoch: 2/4\n","12m 27s (- 12m 23s) (41000 50%) 1.7607\n","12m 46s (- 12m 5s) (42000 51%) 1.7514\n","13m 4s (- 11m 47s) (43000 52%) 1.7687\n","13m 23s (- 11m 29s) (44000 53%) 1.7595\n","13m 41s (- 11m 10s) (45000 55%) 1.6988\n","13m 59s (- 10m 52s) (46000 56%) 1.7281\n","14m 18s (- 10m 34s) (47000 57%) 1.6829\n","14m 36s (- 10m 16s) (48000 58%) 1.7347\n","14m 55s (- 9m 58s) (49000 59%) 1.6440\n","15m 14s (- 9m 40s) (50000 61%) 1.6682\n","15m 32s (- 9m 22s) (51000 62%) 1.6259\n","15m 51s (- 9m 4s) (52000 63%) 1.6696\n","16m 9s (- 8m 45s) (53000 64%) 1.6980\n","16m 28s (- 8m 27s) (54000 66%) 1.5981\n","16m 46s (- 8m 9s) (55000 67%) 1.6316\n","17m 4s (- 7m 51s) (56000 68%) 1.6075\n","17m 23s (- 7m 33s) (57000 69%) 1.6175\n","17m 42s (- 7m 14s) (58000 70%) 1.5711\n","18m 0s (- 6m 56s) (59000 72%) 1.5883\n","18m 19s (- 6m 38s) (60000 73%) 1.5618\n","18m 37s (- 6m 20s) (61000 74%) 1.4981\n","Epoch: 3/4\n","18m 56s (- 6m 1s) (62000 75%) 1.5106\n","19m 14s (- 5m 43s) (63000 77%) 1.4643\n","19m 33s (- 5m 25s) (64000 78%) 1.4683\n","19m 52s (- 5m 7s) (65000 79%) 1.5100\n","20m 10s (- 4m 48s) (66000 80%) 1.4732\n","20m 29s (- 4m 30s) (67000 81%) 1.4347\n","20m 47s (- 4m 12s) (68000 83%) 1.4406\n","21m 6s (- 3m 53s) (69000 84%) 1.4131\n","21m 24s (- 3m 35s) (70000 85%) 1.4261\n","21m 43s (- 3m 17s) (71000 86%) 1.4324\n","22m 1s (- 2m 58s) (72000 88%) 1.4089\n","22m 19s (- 2m 40s) (73000 89%) 1.4834\n","22m 38s (- 2m 22s) (74000 90%) 1.4479\n","22m 56s (- 2m 3s) (75000 91%) 1.4258\n","23m 15s (- 1m 45s) (76000 92%) 1.4411\n","23m 33s (- 1m 27s) (77000 94%) 1.4267\n","23m 52s (- 1m 8s) (78000 95%) 1.3889\n","24m 10s (- 0m 50s) (79000 96%) 1.3967\n","24m 29s (- 0m 32s) (80000 97%) 1.4905\n","24m 47s (- 0m 13s) (81000 99%) 1.3787\n"]}],"source":["hidden_size = 256\n","epochs = 4\n","\n","encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n","\n","trainIters(encoder1, attn_decoder1, epochs, print_every=1000)"]},{"cell_type":"markdown","metadata":{},"source":["#Evaluation randomly"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T07:47:42.678976Z","iopub.status.busy":"2024-02-19T07:47:42.678519Z","iopub.status.idle":"2024-02-19T07:47:42.748269Z","shell.execute_reply":"2024-02-19T07:47:42.747252Z","shell.execute_reply.started":"2024-02-19T07:47:42.678942Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["> nous ne rajeunissons pas .\n","= we re not getting any younger .\n","< we re not getting any any <EOS>\n","\n","> ils sont saouls .\n","= they re drunk .\n","< they re weak . <EOS>\n","\n","> je suis bilingue .\n","= i m bilingual .\n","< i m an electrician . <EOS>\n","\n","> je suis une femme mariee desormais .\n","= i m a married woman now .\n","< i m a married now . <EOS>\n","\n","> je lis un magazine .\n","= i am reading a magazine .\n","< i m reading a magazine . <EOS>\n","\n","> vous me rappelez votre mere .\n","= you remind me of your mother .\n","< you re very disappointed . <EOS>\n","\n","> je vais le prouver .\n","= i m going to prove it .\n","< i m going to the <EOS>\n","\n","> je suis peut etre vieux mais pas fou .\n","= i may be old but i m not crazy .\n","< i may be quite enough to be . <EOS>\n","\n","> je ne suis pas sur de ce que ca veut dire .\n","= i m not sure what it means .\n","< i m not sure that what what s . <EOS>\n","\n","> j en suis certain .\n","= i m sure of that .\n","< i m not certain . <EOS>\n","\n"]}],"source":["evaluateRandomly(encoder1, attn_decoder1)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T07:48:05.964528Z","iopub.status.busy":"2024-02-19T07:48:05.963728Z","iopub.status.idle":"2024-02-19T07:48:26.343557Z","shell.execute_reply":"2024-02-19T07:48:26.342568Z","shell.execute_reply.started":"2024-02-19T07:48:05.964496Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2271/2271 [00:20<00:00, 112.14it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=== Evaluation score - Rouge score ===\n","Rouge1 fmeasure:\t 0.5936495\n","Rouge1 precision:\t 0.56292987\n","Rouge1 recall:  \t 0.6393193\n","Rouge2 fmeasure:\t 0.40064085\n","Rouge2 precision:\t 0.3729596\n","Rouge2 recall:  \t 0.44334692\n","=====================================\n"]}],"source":["input,gt,predict,score = test(encoder1, attn_decoder1, test_pairs)"]},{"cell_type":"markdown","metadata":{},"source":["No-Att Decoder\n","==============="]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T07:48:45.623326Z","iopub.status.busy":"2024-02-19T07:48:45.622375Z","iopub.status.idle":"2024-02-19T07:48:45.632239Z","shell.execute_reply":"2024-02-19T07:48:45.631341Z","shell.execute_reply.started":"2024-02-19T07:48:45.623294Z"},"trusted":true},"outputs":[],"source":["class DecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","        super(DecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        output, hidden = self.gru(embedded, hidden)\n","\n","        output = F.relu(output)\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T07:49:07.324727Z","iopub.status.busy":"2024-02-19T07:49:07.324338Z","iopub.status.idle":"2024-02-19T08:07:27.986285Z","shell.execute_reply":"2024-02-19T08:07:27.985450Z","shell.execute_reply.started":"2024-02-19T07:49:07.324696Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0/4\n","1m 4s (- 16m 22s) (5000 6%) 3.3759\n","2m 9s (- 15m 30s) (10000 12%) 2.9843\n","3m 16s (- 14m 33s) (15000 18%) 2.8260\n","4m 23s (- 13m 34s) (20000 24%) 2.7245\n","Epoch: 1/4\n","5m 31s (- 12m 32s) (25000 30%) 2.5503\n","6m 39s (- 11m 28s) (30000 36%) 2.4608\n","7m 46s (- 10m 23s) (35000 42%) 2.3855\n","8m 54s (- 9m 17s) (40000 48%) 2.3351\n","Epoch: 2/4\n","10m 1s (- 8m 11s) (45000 55%) 2.2244\n","11m 9s (- 7m 5s) (50000 61%) 2.1817\n","12m 17s (- 5m 58s) (55000 67%) 2.1405\n","13m 25s (- 4m 51s) (60000 73%) 2.1081\n","Epoch: 3/4\n","14m 33s (- 3m 45s) (65000 79%) 2.0221\n","15m 41s (- 2m 37s) (70000 85%) 1.9735\n","16m 48s (- 1m 30s) (75000 91%) 1.9466\n","17m 56s (- 0m 23s) (80000 97%) 1.9285\n"]}],"source":["hidden_size = 256\n","epochs = 4\n","\n","encoder2 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","decoder2 = DecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n","\n","trainIters(encoder2, decoder2, epochs, print_every=5000)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T08:07:38.284615Z","iopub.status.busy":"2024-02-19T08:07:38.284222Z","iopub.status.idle":"2024-02-19T08:07:38.359992Z","shell.execute_reply":"2024-02-19T08:07:38.358872Z","shell.execute_reply.started":"2024-02-19T08:07:38.284586Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["> je vous vire .\n","= i m firing you .\n","< i m you you . <EOS>\n","\n","> tu vas devoir faire confiance a tom .\n","= you re going to have to trust tom .\n","< you re going to have to do that . . <EOS>\n","\n","> j achete les billets .\n","= i m buying the tickets .\n","< i m taking a . . <EOS>\n","\n","> nous n allons pas vous faire de mal .\n","= we re not going to hurt you .\n","< we re not going to you . . <EOS>\n","\n","> je vais devoir vous rappeler de suite .\n","= i m going to have to call you right back .\n","< i m going to have to to . . . . <EOS>\n","\n","> vous n avez vraiment pas l ombre d une idee si ?\n","= you really don t have a clue do you ?\n","< you re not really a a a you you you you you <EOS>\n","\n","> il est impatient d y aller .\n","= he is eager to go there .\n","< he is to go to . . <EOS>\n","\n","> il est dans les affaires .\n","= he is in business .\n","< he is in in . . <EOS>\n","\n","> tu es de loin plus rapide que moi .\n","= you re way faster than me .\n","< you re taller than me than me . <EOS>\n","\n","> elle se tenait a cote de lui .\n","= she stood by him .\n","< she sat him to him . <EOS>\n","\n"]}],"source":["evaluateRandomly(encoder2, decoder2)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T08:07:44.083514Z","iopub.status.busy":"2024-02-19T08:07:44.082786Z","iopub.status.idle":"2024-02-19T08:08:02.071281Z","shell.execute_reply":"2024-02-19T08:08:02.070344Z","shell.execute_reply.started":"2024-02-19T08:07:44.083484Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2271/2271 [00:17<00:00, 127.17it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=== Evaluation score - Rouge score ===\n","Rouge1 fmeasure:\t 0.55004895\n","Rouge1 precision:\t 0.530589\n","Rouge1 recall:  \t 0.5803443\n","Rouge2 fmeasure:\t 0.35792232\n","Rouge2 precision:\t 0.3394463\n","Rouge2 recall:  \t 0.38715023\n","=====================================\n"]}],"source":["input,gt,predict,score = test(encoder2, decoder2, test_pairs)"]},{"cell_type":"markdown","metadata":{},"source":["LSTM-encoder and LSTM-decoder\n","============================="]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T08:08:15.538203Z","iopub.status.busy":"2024-02-19T08:08:15.537796Z","iopub.status.idle":"2024-02-19T08:08:15.546293Z","shell.execute_reply":"2024-02-19T08:08:15.545175Z","shell.execute_reply.started":"2024-02-19T08:08:15.538172Z"},"trusted":true},"outputs":[],"source":["class EncoderLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(EncoderLSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.lstm = nn.LSTM(hidden_size, hidden_size)\n","\n","    def forward(self, input, hidden,c):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        output = embedded\n","        output, (hidden,c) = self.lstm(output, (hidden,c))\n","        return output, hidden,c\n","\n","    def initHidden(self):\n","        return (\n","            torch.zeros(1, 1, self.hidden_size, device=device),\n","            torch.zeros(1, 1, self.hidden_size, device=device)\n","        )"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T08:08:18.323070Z","iopub.status.busy":"2024-02-19T08:08:18.322287Z","iopub.status.idle":"2024-02-19T08:08:18.335058Z","shell.execute_reply":"2024-02-19T08:08:18.333969Z","shell.execute_reply.started":"2024-02-19T08:08:18.323034Z"},"trusted":true},"outputs":[],"source":["class AttnDecoderLSTM(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","        super(AttnDecoderLSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden,c, encoder_outputs):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        attn_weights = F.softmax(\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs.unsqueeze(0))\n","\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        output, (hidden,c) = self.lstm(output, (hidden,c))\n","\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden,c\n","\n","    def initHidden(self):\n","        return (\n","            torch.zeros(1, 1, self.hidden_size, device=device),\n","            torch.zeros(1, 1, self.hidden_size, device=device)\n","        )"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T08:08:21.332103Z","iopub.status.busy":"2024-02-19T08:08:21.331603Z","iopub.status.idle":"2024-02-19T08:08:21.343414Z","shell.execute_reply":"2024-02-19T08:08:21.342289Z","shell.execute_reply.started":"2024-02-19T08:08:21.332069Z"},"trusted":true},"outputs":[],"source":["teacher_forcing_ratio = 0.5\n","\n","def train3(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","    encoder_hidden,c = encoder.initHidden()\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","    loss = 0\n","\n","    for ei in range(input_length):\n","        encoder_output, encoder_hidden,c = encoder(\n","            input_tensor[ei], encoder_hidden,c)\n","        encoder_outputs[ei] = encoder_output[0, 0]\n","\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","\n","    decoder_hidden = encoder_hidden\n","\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    if use_teacher_forcing:\n","        # Teacher forcing: Feed the target as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden,c = decoder(\n","                decoder_input, decoder_hidden,c,encoder_outputs)\n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]  # Teacher forcing\n","\n","    else:\n","        # Without teacher forcing: use its own predictions as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden,c = decoder(\n","                decoder_input, decoder_hidden,c, encoder_outputs)\n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","            loss += criterion(decoder_output, target_tensor[di])\n","            if decoder_input.item() == EOS_token:\n","                break\n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T08:08:24.842430Z","iopub.status.busy":"2024-02-19T08:08:24.842046Z","iopub.status.idle":"2024-02-19T08:08:24.852576Z","shell.execute_reply":"2024-02-19T08:08:24.851646Z","shell.execute_reply.started":"2024-02-19T08:08:24.842401Z"},"trusted":true},"outputs":[],"source":["def trainIters3(encoder, decoder, epochs, print_every=1000, plot_every=100, learning_rate=0.01):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","\n","    criterion = nn.NLLLoss()\n","\n","    iter = 1\n","    n_iters = len(train_pairs) * epochs\n","\n","    for epoch in range(epochs):\n","        print(\"Epoch: %d/%d\" % (epoch, epochs))\n","        for training_pair in train_pairs:\n","            training_pair = tensorsFromPair(training_pair)\n","\n","            input_tensor = training_pair[0]\n","            target_tensor = training_pair[1]\n","\n","            loss = train3(input_tensor, target_tensor, encoder,\n","                        decoder, encoder_optimizer, decoder_optimizer, criterion)\n","            print_loss_total += loss\n","            plot_loss_total += loss\n","\n","            if iter % print_every == 0:\n","                print_loss_avg = print_loss_total / print_every\n","                print_loss_total = 0\n","                print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n","                                            iter, iter / n_iters * 100, print_loss_avg))\n","\n","            if iter % plot_every == 0:\n","                plot_loss_avg = plot_loss_total / plot_every\n","                plot_losses.append(plot_loss_avg)\n","                plot_loss_total = 0\n","\n","            iter +=1\n","\n","    showPlot(plot_losses)"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T08:08:28.518793Z","iopub.status.busy":"2024-02-19T08:08:28.517913Z","iopub.status.idle":"2024-02-19T08:35:59.997887Z","shell.execute_reply":"2024-02-19T08:35:59.997035Z","shell.execute_reply.started":"2024-02-19T08:08:28.518762Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0/4\n","1m 36s (- 24m 39s) (5000 6%) 3.4390\n","3m 16s (- 23m 27s) (10000 12%) 3.0061\n","4m 56s (- 21m 58s) (15000 18%) 2.7932\n","6m 37s (- 20m 28s) (20000 24%) 2.6290\n","Epoch: 1/4\n","8m 18s (- 18m 52s) (25000 30%) 2.4123\n","9m 59s (- 17m 14s) (30000 36%) 2.2959\n","11m 40s (- 15m 36s) (35000 42%) 2.1949\n","13m 22s (- 13m 58s) (40000 48%) 2.1214\n","Epoch: 2/4\n","15m 4s (- 12m 18s) (45000 55%) 1.9858\n","16m 45s (- 10m 38s) (50000 61%) 1.9188\n","18m 27s (- 8m 58s) (55000 67%) 1.8562\n","20m 9s (- 7m 18s) (60000 73%) 1.8180\n","Epoch: 3/4\n","21m 50s (- 5m 37s) (65000 79%) 1.7084\n","23m 32s (- 3m 57s) (70000 85%) 1.6483\n","25m 13s (- 2m 16s) (75000 91%) 1.6072\n","26m 55s (- 0m 35s) (80000 97%) 1.5848\n"]}],"source":["hidden_size = 256\n","epochs = 4\n","\n","encoder3 = EncoderLSTM(input_lang.n_words, hidden_size).to(device)\n","decoder3 = AttnDecoderLSTM(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n","\n","trainIters3(encoder3, decoder3, epochs, print_every=5000)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T08:36:25.814434Z","iopub.status.busy":"2024-02-19T08:36:25.814042Z","iopub.status.idle":"2024-02-19T08:36:25.824521Z","shell.execute_reply":"2024-02-19T08:36:25.823673Z","shell.execute_reply.started":"2024-02-19T08:36:25.814405Z"},"trusted":true},"outputs":[],"source":["def evaluate3(encoder, decoder, sentence, max_length=MAX_LENGTH):\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(input_lang, sentence)\n","        input_length = input_tensor.size()[0]\n","        encoder_hidden,c = encoder.initHidden()\n","\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden,c = encoder(input_tensor[ei],\n","                                                     encoder_hidden,c)\n","            encoder_outputs[ei] += encoder_output[0, 0]\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","\n","        decoded_words = []\n","\n","        for di in range(max_length):\n","            decoder_output, decoder_hidden,c = decoder(\n","                decoder_input, decoder_hidden,c,encoder_outputs)\n","\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T08:36:28.445243Z","iopub.status.busy":"2024-02-19T08:36:28.444376Z","iopub.status.idle":"2024-02-19T08:36:28.450912Z","shell.execute_reply":"2024-02-19T08:36:28.449889Z","shell.execute_reply.started":"2024-02-19T08:36:28.445212Z"},"trusted":true},"outputs":[],"source":["def evaluateRandomly3(encoder, decoder, n=10):\n","    for i in range(n):\n","        pair = random.choice(pairs)\n","        print('>', pair[0])\n","        print('=', pair[1])\n","        output_words = evaluate3(encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words)\n","        print('<', output_sentence)\n","        print('')"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T08:36:31.142270Z","iopub.status.busy":"2024-02-19T08:36:31.141892Z","iopub.status.idle":"2024-02-19T08:36:31.156001Z","shell.execute_reply":"2024-02-19T08:36:31.155071Z","shell.execute_reply.started":"2024-02-19T08:36:31.142241Z"},"trusted":true},"outputs":[],"source":["from torchmetrics.text.rouge import ROUGEScore\n","from tqdm import tqdm\n","\n","rouge = ROUGEScore()\n","\n","def test3(encoder, decoder, testing_pairs):\n","    input = []\n","    gt = []\n","    predict = []\n","    metric_score = {\n","        \"rouge1_fmeasure\":[],\n","        \"rouge1_precision\":[],\n","        \"rouge1_recall\":[],\n","        \"rouge2_fmeasure\":[],\n","        \"rouge2_precision\":[],\n","        \"rouge2_recall\":[]\n","    }\n","    from tqdm import tqdm\n","    for i in tqdm(range(len(testing_pairs))):\n","        pair = testing_pairs[i]\n","        output_words = evaluate3(encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words)\n","\n","        input.append(pair[0])\n","        gt.append(pair[1])\n","        predict.append(output_sentence)\n","\n","        try:\n","            rs = rouge(output_sentence, pair[1])\n","        except:\n","            continue\n","        metric_score[\"rouge1_fmeasure\"].append(rs['rouge1_fmeasure'])\n","        metric_score[\"rouge1_precision\"].append(rs['rouge1_precision'])\n","        metric_score[\"rouge1_recall\"].append(rs['rouge1_recall'])\n","        metric_score[\"rouge2_fmeasure\"].append(rs['rouge2_fmeasure'])\n","        metric_score[\"rouge2_precision\"].append(rs['rouge2_precision'])\n","        metric_score[\"rouge2_recall\"].append(rs['rouge2_recall'])\n","\n","    metric_score[\"rouge1_fmeasure\"] = np.array(metric_score[\"rouge1_fmeasure\"]).mean()\n","    metric_score[\"rouge1_precision\"] = np.array(metric_score[\"rouge1_precision\"]).mean()\n","    metric_score[\"rouge1_recall\"] = np.array(metric_score[\"rouge1_recall\"]).mean()\n","    metric_score[\"rouge2_fmeasure\"] = np.array(metric_score[\"rouge2_fmeasure\"]).mean()\n","    metric_score[\"rouge2_precision\"] = np.array(metric_score[\"rouge2_precision\"]).mean()\n","    metric_score[\"rouge2_recall\"] = np.array(metric_score[\"rouge2_recall\"]).mean()\n","\n","    print(\"=== Evaluation score - Rouge score ===\")\n","    print(\"Rouge1 fmeasure:\\t\",metric_score[\"rouge1_fmeasure\"])\n","    print(\"Rouge1 precision:\\t\",metric_score[\"rouge1_precision\"])\n","    print(\"Rouge1 recall:  \\t\",metric_score[\"rouge1_recall\"])\n","    print(\"Rouge2 fmeasure:\\t\",metric_score[\"rouge2_fmeasure\"])\n","    print(\"Rouge2 precision:\\t\",metric_score[\"rouge2_precision\"])\n","    print(\"Rouge2 recall:  \\t\",metric_score[\"rouge2_recall\"])\n","    print(\"=====================================\")\n","    return input,gt,predict,metric_score"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T08:36:35.171477Z","iopub.status.busy":"2024-02-19T08:36:35.170774Z","iopub.status.idle":"2024-02-19T08:36:35.246240Z","shell.execute_reply":"2024-02-19T08:36:35.245309Z","shell.execute_reply.started":"2024-02-19T08:36:35.171446Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["> je suis habitue a cet ordinateur .\n","= i m used to this computer .\n","< i m accustomed to this . <EOS>\n","\n","> tu as bonne mine !\n","= you re looking good !\n","< you re looking good ! <EOS>\n","\n","> il etudie le chinois .\n","= he studies chinese .\n","< he stopped in the . <EOS>\n","\n","> nous vous protegeons .\n","= we re protecting you .\n","< we re waiting . <EOS>\n","\n","> vous ne saisissez pas .\n","= you re missing the point .\n","< you re not listening any . <EOS>\n","\n","> vous etes fort emotives .\n","= you re very emotional .\n","< you re very good . <EOS>\n","\n","> je suis terrifie .\n","= i m terrified .\n","< i m a . <EOS>\n","\n","> ils sont vraiment radins .\n","= they re really tight .\n","< they re really surprised . <EOS>\n","\n","> je ne suis pas sur que vous soyez prete .\n","= i m not sure that you re ready .\n","< i m not sure that you re ready . <EOS>\n","\n","> il a etabli des amities avec les gens les plus improbables .\n","= he struck up friendships with the most unlikely people .\n","< he is with with with with with . . <EOS>\n","\n"]}],"source":["evaluateRandomly3(encoder3, decoder3)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T08:36:53.762252Z","iopub.status.busy":"2024-02-19T08:36:53.761893Z","iopub.status.idle":"2024-02-19T08:37:15.200403Z","shell.execute_reply":"2024-02-19T08:37:15.199520Z","shell.execute_reply.started":"2024-02-19T08:36:53.762226Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2271/2271 [00:21<00:00, 106.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=== Evaluation score - Rouge score ===\n","Rouge1 fmeasure:\t 0.5957047\n","Rouge1 precision:\t 0.56564856\n","Rouge1 recall:  \t 0.63748354\n","Rouge2 fmeasure:\t 0.40394336\n","Rouge2 precision:\t 0.37731498\n","Rouge2 recall:  \t 0.44290024\n","=====================================\n"]}],"source":["input,gt,predict,score = test3(encoder3, decoder3, test_pairs)"]},{"cell_type":"markdown","metadata":{},"source":["BiLSTM-encoder\n","=============="]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:45:58.909180Z","iopub.status.busy":"2024-02-19T22:45:58.908259Z","iopub.status.idle":"2024-02-19T22:45:58.918399Z","shell.execute_reply":"2024-02-19T22:45:58.917379Z","shell.execute_reply.started":"2024-02-19T22:45:58.909147Z"},"trusted":true},"outputs":[],"source":["class EncoderBiLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(EncoderBiLSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.lstm = nn.LSTM(hidden_size, hidden_size,bidirectional=True)\n","\n","    def forward(self, input, hidden,c):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        output = embedded\n","        output, (hidden,c) = self.lstm(output, (hidden,c))\n","        return output, hidden,c\n","\n","    def initHidden(self):\n","        return (\n","            torch.zeros(2, 1, self.hidden_size, device=device),\n","            torch.zeros(2, 1, self.hidden_size, device=device)\n","        )"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:46:04.140683Z","iopub.status.busy":"2024-02-19T22:46:04.139902Z","iopub.status.idle":"2024-02-19T22:46:04.151799Z","shell.execute_reply":"2024-02-19T22:46:04.150882Z","shell.execute_reply.started":"2024-02-19T22:46:04.140652Z"},"trusted":true},"outputs":[],"source":["class AttnDecoderRNN4(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","        super(AttnDecoderRNN4, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","        self.attn_combine = nn.Linear(self.hidden_size * 2+self.hidden_size, self.hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        attn_weights = F.softmax(\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs.unsqueeze(0))\n","\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device),\n","           "]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:46:06.582260Z","iopub.status.busy":"2024-02-19T22:46:06.581635Z","iopub.status.idle":"2024-02-19T22:46:06.592978Z","shell.execute_reply":"2024-02-19T22:46:06.591999Z","shell.execute_reply.started":"2024-02-19T22:46:06.582229Z"},"trusted":true},"outputs":[],"source":["teacher_forcing_ratio = 0.5\n","\n","def train4(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","    encoder_hidden,c = encoder.initHidden()\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size*2, device=device)\n","\n","    loss = 0\n","\n","    for ei in range(input_length):\n","        encoder_output, encoder_hidden,c = encoder(\n","            input_tensor[ei], encoder_hidden,c)\n","        encoder_outputs[ei] = encoder_output[0, 0]\n","\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","\n","    decoder_hidden = encoder_hidden.mean(dim=0,keepdim=True)\n","\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    if use_teacher_forcing:\n","        # Teacher forcing: Feed the target as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]  # Teacher forcing\n","\n","    else:\n","        # Without teacher forcing: use its own predictions as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","            loss += criterion(decoder_output, target_tensor[di])\n","            if decoder_input.item() == EOS_token:\n","                break\n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:46:10.078349Z","iopub.status.busy":"2024-02-19T22:46:10.078005Z","iopub.status.idle":"2024-02-19T22:46:10.088241Z","shell.execute_reply":"2024-02-19T22:46:10.087259Z","shell.execute_reply.started":"2024-02-19T22:46:10.078323Z"},"trusted":true},"outputs":[],"source":["def trainIters4(encoder, decoder, epochs, print_every=1000, plot_every=100, learning_rate=0.01):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","\n","    criterion = nn.NLLLoss()\n","\n","    iter = 1\n","    n_iters = len(train_pairs) * epochs\n","\n","    for epoch in range(epochs):\n","        print(\"Epoch: %d/%d\" % (epoch, epochs))\n","        for training_pair in train_pairs:\n","            training_pair = tensorsFromPair(training_pair)\n","\n","            input_tensor = training_pair[0]\n","            target_tensor = training_pair[1]\n","\n","            loss = train4(input_tensor, target_tensor, encoder,\n","                        decoder, encoder_optimizer, decoder_optimizer, criterion)\n","            print_loss_total += loss\n","            plot_loss_total += loss\n","\n","            if iter % print_every == 0:\n","                print_loss_avg = print_loss_total / print_every\n","                print_loss_total = 0\n","                print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n","                                            iter, iter / n_iters * 100, print_loss_avg))\n","\n","            if iter % plot_every == 0:\n","                plot_loss_avg = plot_loss_total / plot_every\n","                plot_losses.append(plot_loss_avg)\n","                plot_loss_total = 0\n","\n","            iter +=1\n","\n","    showPlot(plot_losses)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:46:19.350704Z","iopub.status.busy":"2024-02-19T22:46:19.350299Z","iopub.status.idle":"2024-02-19T22:46:19.360999Z","shell.execute_reply":"2024-02-19T22:46:19.360006Z","shell.execute_reply.started":"2024-02-19T22:46:19.350658Z"},"trusted":true},"outputs":[],"source":["def evaluate4(encoder, decoder, sentence, max_length=MAX_LENGTH):\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(input_lang, sentence)\n","        input_length = input_tensor.size()[0]\n","        encoder_hidden,c = encoder.initHidden()\n","\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size*2, device=device)\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden,c = encoder(input_tensor[ei],\n","                                                     encoder_hidden,c)\n","            encoder_outputs[ei] += encoder_output[0, 0]\n","    \n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden.mean(dim=0,keepdim=True)\n","        decoded_words = []\n","\n","        for di in range(max_length):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:46:23.398361Z","iopub.status.busy":"2024-02-19T22:46:23.397985Z","iopub.status.idle":"2024-02-19T22:46:23.404247Z","shell.execute_reply":"2024-02-19T22:46:23.403298Z","shell.execute_reply.started":"2024-02-19T22:46:23.398330Z"},"trusted":true},"outputs":[],"source":["def evaluateRandomly4(encoder, decoder, n=10):\n","    for i in range(n):\n","        pair = random.choice(pairs)\n","        print('>', pair[0])\n","        print('=', pair[1])\n","        output_words = evaluate4(encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words)\n","        print('<', output_sentence)\n","        print('')"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:46:26.165088Z","iopub.status.busy":"2024-02-19T22:46:26.164670Z","iopub.status.idle":"2024-02-19T22:46:26.178469Z","shell.execute_reply":"2024-02-19T22:46:26.177562Z","shell.execute_reply.started":"2024-02-19T22:46:26.165051Z"},"trusted":true},"outputs":[],"source":["from torchmetrics.text.rouge import ROUGEScore\n","from tqdm import tqdm\n","\n","rouge = ROUGEScore()\n","\n","def test4(encoder, decoder, testing_pairs):\n","    input = []\n","    gt = []\n","    predict = []\n","    metric_score = {\n","        \"rouge1_fmeasure\":[],\n","        \"rouge1_precision\":[],\n","        \"rouge1_recall\":[],\n","        \"rouge2_fmeasure\":[],\n","        \"rouge2_precision\":[],\n","        \"rouge2_recall\":[]\n","    }\n","    from tqdm import tqdm\n","    for i in tqdm(range(len(testing_pairs))):\n","        pair = testing_pairs[i]\n","        output_words = evaluate4(encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words)\n","\n","        input.append(pair[0])\n","        gt.append(pair[1])\n","        predict.append(output_sentence)\n","\n","        try:\n","            rs = rouge(output_sentence, pair[1])\n","        except:\n","            continue\n","        metric_score[\"rouge1_fmeasure\"].append(rs['rouge1_fmeasure'])\n","        metric_score[\"rouge1_precision\"].append(rs['rouge1_precision'])\n","        metric_score[\"rouge1_recall\"].append(rs['rouge1_recall'])\n","        metric_score[\"rouge2_fmeasure\"].append(rs['rouge2_fmeasure'])\n","        metric_score[\"rouge2_precision\"].append(rs['rouge2_precision'])\n","        metric_score[\"rouge2_recall\"].append(rs['rouge2_recall'])\n","\n","    metric_score[\"rouge1_fmeasure\"] = np.array(metric_score[\"rouge1_fmeasure\"]).mean()\n","    metric_score[\"rouge1_precision\"] = np.array(metric_score[\"rouge1_precision\"]).mean()\n","    metric_score[\"rouge1_recall\"] = np.array(metric_score[\"rouge1_recall\"]).mean()\n","    metric_score[\"rouge2_fmeasure\"] = np.array(metric_score[\"rouge2_fmeasure\"]).mean()\n","    metric_score[\"rouge2_precision\"] = np.array(metric_score[\"rouge2_precision\"]).mean()\n","    metric_score[\"rouge2_recall\"] = np.array(metric_score[\"rouge2_recall\"]).mean()\n","\n","    print(\"=== Evaluation score - Rouge score ===\")\n","    print(\"Rouge1 fmeasure:\\t\",metric_score[\"rouge1_fmeasure\"])\n","    print(\"Rouge1 precision:\\t\",metric_score[\"rouge1_precision\"])\n","    print(\"Rouge1 recall:  \\t\",metric_score[\"rouge1_recall\"])\n","    print(\"Rouge2 fmeasure:\\t\",metric_score[\"rouge2_fmeasure\"])\n","    print(\"Rouge2 precision:\\t\",metric_score[\"rouge2_precision\"])\n","    print(\"Rouge2 recall:  \\t\",metric_score[\"rouge2_recall\"])\n","    print(\"=====================================\")\n","    return input,gt,predict,metric_score"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T22:46:29.821954Z","iopub.status.busy":"2024-02-19T22:46:29.821540Z","iopub.status.idle":"2024-02-19T23:27:26.778075Z","shell.execute_reply":"2024-02-19T23:27:26.777267Z","shell.execute_reply.started":"2024-02-19T22:46:29.821908Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0/6\n","1m 34s (- 37m 12s) (5000 4%) 3.3593\n","3m 11s (- 35m 58s) (10000 8%) 2.9314\n","4m 49s (- 34m 37s) (15000 12%) 2.7352\n","6m 27s (- 33m 10s) (20000 16%) 2.5547\n","Epoch: 1/6\n","8m 6s (- 31m 40s) (25000 20%) 2.3475\n","9m 44s (- 30m 4s) (30000 24%) 2.2286\n","11m 23s (- 28m 31s) (35000 28%) 2.1320\n","13m 2s (- 26m 55s) (40000 32%) 2.0608\n","Epoch: 2/6\n","14m 40s (- 25m 18s) (45000 36%) 1.9184\n","16m 19s (- 23m 42s) (50000 40%) 1.8578\n","17m 58s (- 22m 5s) (55000 44%) 1.7912\n","19m 37s (- 20m 28s) (60000 48%) 1.7528\n","Epoch: 3/6\n","21m 16s (- 18m 51s) (65000 53%) 1.6511\n","22m 59s (- 17m 16s) (70000 57%) 1.6130\n","24m 42s (- 15m 41s) (75000 61%) 1.5643\n","26m 25s (- 14m 4s) (80000 65%) 1.5532\n","Epoch: 4/6\n","28m 8s (- 12m 27s) (85000 69%) 1.4582\n","29m 50s (- 10m 48s) (90000 73%) 1.4232\n","31m 31s (- 9m 10s) (95000 77%) 1.3918\n","33m 13s (- 7m 31s) (100000 81%) 1.4171\n","Epoch: 5/6\n","34m 57s (- 5m 51s) (105000 85%) 1.3413\n","36m 39s (- 4m 12s) (110000 89%) 1.2958\n","38m 21s (- 2m 32s) (115000 93%) 1.2664\n","40m 4s (- 0m 52s) (120000 97%) 1.2644\n"]}],"source":["hidden_size = 256\n","epochs = 6\n","\n","encoder4 = EncoderBiLSTM(input_lang.n_words, hidden_size).to(device)\n","decoder4 = AttnDecoderRNN4(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n","\n","trainIters4(encoder4, decoder4, epochs, print_every=5000)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T23:27:33.127790Z","iopub.status.busy":"2024-02-19T23:27:33.127193Z","iopub.status.idle":"2024-02-19T23:27:33.215035Z","shell.execute_reply":"2024-02-19T23:27:33.214148Z","shell.execute_reply.started":"2024-02-19T23:27:33.127758Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["> je te libere .\n","= i m letting you go .\n","< i m leaving you . <EOS>\n","\n","> vous etes mon seul veritable ami .\n","= you re my only real friend .\n","< you re my only real friend . <EOS>\n","\n","> elle est plus vieille que toi de deux ans .\n","= she is two years older than you .\n","< she is two years older than you . <EOS>\n","\n","> je suis le chef de cette equipe .\n","= i m the leader of this team .\n","< i m the s of this team . <EOS>\n","\n","> il fait ca depuis plus de vingt ans .\n","= he s been doing this for over twenty years .\n","< he s been as this s s than you . <EOS>\n","\n","> tu es sur la liste n est ce pas ?\n","= you re on the list aren t you ?\n","< you re worried about you you ? <EOS>\n","\n","> tu n es pas mariee si ?\n","= you re not married are you ?\n","< you re not married are you ? <EOS>\n","\n","> si j ai offusque quelqu un je m en excuse .\n","= i m sorry if i offended anyone .\n","< i m quite someone because i m . <EOS>\n","\n","> ce n est pas un mauvais bougre .\n","= he s not a bad guy .\n","< he is not a bad guy . <EOS>\n","\n","> je suis etudiant en deuxieme annee .\n","= i m a second year student .\n","< i m a student year . <EOS>\n","\n"]}],"source":["evaluateRandomly4(encoder4, decoder4)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-02-19T23:27:39.641990Z","iopub.status.busy":"2024-02-19T23:27:39.641615Z","iopub.status.idle":"2024-02-19T23:28:00.828846Z","shell.execute_reply":"2024-02-19T23:28:00.827867Z","shell.execute_reply.started":"2024-02-19T23:27:39.641945Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2271/2271 [00:21<00:00, 107.82it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=== Evaluation score - Rouge score ===\n","Rouge1 fmeasure:\t 0.6059015\n","Rouge1 precision:\t 0.57410693\n","Rouge1 recall:  \t 0.6513969\n","Rouge2 fmeasure:\t 0.4183748\n","Rouge2 precision:\t 0.39016286\n","Rouge2 recall:  \t 0.46071836\n","=====================================\n"]}],"source":["input,gt,predict,score = test4(encoder4, decoder4, test_pairs)"]},{"cell_type":"markdown","metadata":{},"source":["Transformer-encoder\n","=================="]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T01:15:30.073770Z","iopub.status.busy":"2024-02-20T01:15:30.073096Z","iopub.status.idle":"2024-02-20T01:15:30.085773Z","shell.execute_reply":"2024-02-20T01:15:30.084757Z","shell.execute_reply.started":"2024-02-20T01:15:30.073737Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer\n","\n","class EncoderTransformer(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers):\n","        super(EncoderTransformer, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.pos_encoding = PositionalEncoding(hidden_size)\n","        encoder_layer = TransformerEncoderLayer(hidden_size, nhead=8)\n","        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers)\n","\n","    def forward(self, input):\n","        embedded = self.embedding(input)  # [seq_len, batch_size, hidden_size]\n","        embedded = embedded * math.sqrt(self.hidden_size)\n","        embedded = self.pos_encoding(embedded)\n","        output = self.transformer_encoder(embedded)  # [seq_len, batch_size, hidden_size]\n","        return output\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, hidden_size, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=0.1)\n","        pe = torch.zeros(max_len, hidden_size)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, hidden_size, 2).float() * (-math.log(10000.0) / hidden_size))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T01:15:32.386943Z","iopub.status.busy":"2024-02-20T01:15:32.386250Z","iopub.status.idle":"2024-02-20T01:15:32.397993Z","shell.execute_reply":"2024-02-20T01:15:32.396943Z","shell.execute_reply.started":"2024-02-20T01:15:32.386892Z"},"trusted":true},"outputs":[],"source":["class AttnDecoderRNN5(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","        super(AttnDecoderRNN5, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        attn_weights = F.softmax(\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs)\n","\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T01:15:34.819074Z","iopub.status.busy":"2024-02-20T01:15:34.818153Z","iopub.status.idle":"2024-02-20T01:15:34.834720Z","shell.execute_reply":"2024-02-20T01:15:34.833465Z","shell.execute_reply.started":"2024-02-20T01:15:34.819028Z"},"trusted":true},"outputs":[],"source":["teacher_forcing_ratio = 0.5\n","def train5(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","    \n","    loss = 0\n","\n","#     for ei in range(input_length):\n","#         encoder_output = encoder(input_tensor[ei])\n","#         encoder_outputs[ei] = encoder_output[0, 0]\n","    \n","    encoder_output = encoder(input_tensor)\n","    encoder_output = encoder_output.squeeze(1)\n","    encoder_outputs[:input_length,:]+=encoder_output\n","    encoder_outputs = encoder_outputs.unsqueeze(0)\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","\n","    decoder_hidden = encoder_outputs[:,-1,:].unsqueeze(0)\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    if use_teacher_forcing:\n","        # Teacher forcing: Feed the target as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]  # Teacher forcing\n","\n","    else:\n","        # Without teacher forcing: use its own predictions as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","            loss += criterion(decoder_output, target_tensor[di])\n","            if decoder_input.item() == EOS_token:\n","                break\n","\n","    loss.backward()\n","    \n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T01:15:37.373900Z","iopub.status.busy":"2024-02-20T01:15:37.373529Z","iopub.status.idle":"2024-02-20T01:15:37.384124Z","shell.execute_reply":"2024-02-20T01:15:37.383092Z","shell.execute_reply.started":"2024-02-20T01:15:37.373869Z"},"trusted":true},"outputs":[],"source":["def trainIters5(encoder, decoder, epochs, print_every=1000, plot_every=100, learning_rate=0.01):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(),lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(),lr = learning_rate)\n","\n","    criterion = nn.NLLLoss()\n","\n","    iter = 1\n","    n_iters = len(train_pairs) * epochs\n","\n","    for epoch in range(epochs):\n","        print(\"Epoch: %d/%d\" % (epoch, epochs))\n","        for training_pair in train_pairs:\n","            training_pair = tensorsFromPair(training_pair)\n","\n","            input_tensor = training_pair[0]\n","            target_tensor = training_pair[1]\n","\n","            loss = train5(input_tensor, target_tensor, encoder,\n","                        decoder, encoder_optimizer, decoder_optimizer, criterion)\n","            print_loss_total += loss\n","            plot_loss_total += loss\n","\n","            if iter % print_every == 0:\n","                print_loss_avg = print_loss_total / print_every\n","                print_loss_total = 0\n","                print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n","                                            iter, iter / n_iters * 100, print_loss_avg))\n","\n","            if iter % plot_every == 0:\n","                plot_loss_avg = plot_loss_total / plot_every\n","                plot_losses.append(plot_loss_avg)\n","                plot_loss_total = 0\n","\n","            iter +=1\n","\n","    showPlot(plot_losses)"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T01:15:39.440258Z","iopub.status.busy":"2024-02-20T01:15:39.439589Z","iopub.status.idle":"2024-02-20T01:15:39.449021Z","shell.execute_reply":"2024-02-20T01:15:39.448005Z","shell.execute_reply.started":"2024-02-20T01:15:39.440225Z"},"trusted":true},"outputs":[],"source":["def evaluate5(encoder, decoder, sentence, max_length=MAX_LENGTH):\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(input_lang, sentence)\n","        input_length = input_tensor.size()[0]\n","        \n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","#         for ei in range(input_length):\n","#             encoder_output = encoder(input_tensor[ei])\n","#             encoder_outputs[ei] += encoder_output[0, 0]\n","\n","        encoder_output = encoder(input_tensor)\n","        encoder_output = encoder_output.squeeze(1)\n","        encoder_outputs[:input_length,:]+=encoder_output\n","        encoder_outputs = encoder_outputs.unsqueeze(0)\n","\n","        decoder_hidden = encoder_outputs[:,-1,:].unsqueeze(0)\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoded_words = []\n","\n","        for di in range(max_length):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words"]},{"cell_type":"code","execution_count":83,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T01:15:41.667594Z","iopub.status.busy":"2024-02-20T01:15:41.667230Z","iopub.status.idle":"2024-02-20T01:15:41.673872Z","shell.execute_reply":"2024-02-20T01:15:41.672768Z","shell.execute_reply.started":"2024-02-20T01:15:41.667568Z"},"trusted":true},"outputs":[],"source":["def evaluateRandomly5(encoder, decoder, n=10):\n","    for i in range(n):\n","        pair = random.choice(pairs)\n","        print('>', pair[0])\n","        print('=', pair[1])\n","        output_words = evaluate5(encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words)\n","        print('<', output_sentence)\n","        print('')"]},{"cell_type":"code","execution_count":84,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T01:15:44.467712Z","iopub.status.busy":"2024-02-20T01:15:44.467060Z","iopub.status.idle":"2024-02-20T01:15:44.481817Z","shell.execute_reply":"2024-02-20T01:15:44.480960Z","shell.execute_reply.started":"2024-02-20T01:15:44.467680Z"},"trusted":true},"outputs":[],"source":["from torchmetrics.text.rouge import ROUGEScore\n","from tqdm import tqdm\n","\n","rouge = ROUGEScore()\n","\n","def test5(encoder, decoder, testing_pairs):\n","    input = []\n","    gt = []\n","    predict = []\n","    metric_score = {\n","        \"rouge1_fmeasure\":[],\n","        \"rouge1_precision\":[],\n","        \"rouge1_recall\":[],\n","        \"rouge2_fmeasure\":[],\n","        \"rouge2_precision\":[],\n","        \"rouge2_recall\":[]\n","    }\n","    from tqdm import tqdm\n","    for i in tqdm(range(len(testing_pairs))):\n","        pair = testing_pairs[i]\n","        output_words = evaluate5(encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words)\n","\n","        input.append(pair[0])\n","        gt.append(pair[1])\n","        predict.append(output_sentence)\n","\n","        try:\n","            rs = rouge(output_sentence, pair[1])\n","        except:\n","            continue\n","        metric_score[\"rouge1_fmeasure\"].append(rs['rouge1_fmeasure'])\n","        metric_score[\"rouge1_precision\"].append(rs['rouge1_precision'])\n","        metric_score[\"rouge1_recall\"].append(rs['rouge1_recall'])\n","        metric_score[\"rouge2_fmeasure\"].append(rs['rouge2_fmeasure'])\n","        metric_score[\"rouge2_precision\"].append(rs['rouge2_precision'])\n","        metric_score[\"rouge2_recall\"].append(rs['rouge2_recall'])\n","\n","    metric_score[\"rouge1_fmeasure\"] = np.array(metric_score[\"rouge1_fmeasure\"]).mean()\n","    metric_score[\"rouge1_precision\"] = np.array(metric_score[\"rouge1_precision\"]).mean()\n","    metric_score[\"rouge1_recall\"] = np.array(metric_score[\"rouge1_recall\"]).mean()\n","    metric_score[\"rouge2_fmeasure\"] = np.array(metric_score[\"rouge2_fmeasure\"]).mean()\n","    metric_score[\"rouge2_precision\"] = np.array(metric_score[\"rouge2_precision\"]).mean()\n","    metric_score[\"rouge2_recall\"] = np.array(metric_score[\"rouge2_recall\"]).mean()\n","\n","    print(\"=== Evaluation score - Rouge score ===\")\n","    print(\"Rouge1 fmeasure:\\t\",metric_score[\"rouge1_fmeasure\"])\n","    print(\"Rouge1 precision:\\t\",metric_score[\"rouge1_precision\"])\n","    print(\"Rouge1 recall:  \\t\",metric_score[\"rouge1_recall\"])\n","    print(\"Rouge2 fmeasure:\\t\",metric_score[\"rouge2_fmeasure\"])\n","    print(\"Rouge2 precision:\\t\",metric_score[\"rouge2_precision\"])\n","    print(\"Rouge2 recall:  \\t\",metric_score[\"rouge2_recall\"])\n","    print(\"=====================================\")\n","    return input,gt,predict,metric_score"]},{"cell_type":"code","execution_count":85,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T01:15:50.297965Z","iopub.status.busy":"2024-02-20T01:15:50.297143Z","iopub.status.idle":"2024-02-20T01:45:44.369646Z","shell.execute_reply":"2024-02-20T01:45:44.368838Z","shell.execute_reply.started":"2024-02-20T01:15:50.297917Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0/4\n","0m 20s (- 27m 1s) (1000 1%) 3.7144\n","0m 41s (- 27m 15s) (2000 2%) 3.2865\n","1m 2s (- 27m 21s) (3000 3%) 3.1841\n","1m 24s (- 27m 14s) (4000 4%) 3.1072\n","1m 45s (- 26m 59s) (5000 6%) 3.0407\n","2m 6s (- 26m 40s) (6000 7%) 2.9831\n","2m 28s (- 26m 23s) (7000 8%) 2.9948\n","2m 49s (- 26m 6s) (8000 9%) 2.9158\n","3m 11s (- 25m 48s) (9000 11%) 2.8825\n","3m 33s (- 25m 29s) (10000 12%) 2.8077\n","3m 54s (- 25m 10s) (11000 13%) 2.8135\n","4m 16s (- 24m 52s) (12000 14%) 2.8400\n","4m 38s (- 24m 33s) (13000 15%) 2.7501\n","5m 0s (- 24m 13s) (14000 17%) 2.6982\n","5m 21s (- 23m 52s) (15000 18%) 2.6678\n","5m 43s (- 23m 32s) (16000 19%) 2.6825\n","6m 5s (- 23m 12s) (17000 20%) 2.6682\n","6m 27s (- 22m 51s) (18000 22%) 2.5803\n","6m 49s (- 22m 31s) (19000 23%) 2.6527\n","7m 10s (- 22m 10s) (20000 24%) 2.5777\n","Epoch: 1/4\n","7m 32s (- 21m 49s) (21000 25%) 2.5311\n","7m 54s (- 21m 29s) (22000 26%) 2.5026\n","8m 16s (- 21m 8s) (23000 28%) 2.5082\n","8m 38s (- 20m 47s) (24000 29%) 2.4449\n","9m 0s (- 20m 25s) (25000 30%) 2.4305\n","9m 21s (- 20m 4s) (26000 31%) 2.4031\n","9m 43s (- 19m 43s) (27000 33%) 2.4187\n","10m 5s (- 19m 22s) (28000 34%) 2.4238\n","10m 27s (- 19m 0s) (29000 35%) 2.3640\n","10m 48s (- 18m 39s) (30000 36%) 2.3951\n","11m 10s (- 18m 17s) (31000 37%) 2.3608\n","11m 32s (- 17m 56s) (32000 39%) 2.3600\n","11m 54s (- 17m 35s) (33000 40%) 2.3620\n","12m 16s (- 17m 13s) (34000 41%) 2.3270\n","12m 37s (- 16m 52s) (35000 42%) 2.3098\n","12m 59s (- 16m 30s) (36000 44%) 2.3222\n","13m 21s (- 16m 8s) (37000 45%) 2.2675\n","13m 42s (- 15m 47s) (38000 46%) 2.2410\n","14m 5s (- 15m 26s) (39000 47%) 2.3101\n","14m 27s (- 15m 5s) (40000 48%) 2.2457\n","Epoch: 2/4\n","14m 49s (- 14m 44s) (41000 50%) 2.2103\n","15m 11s (- 14m 22s) (42000 51%) 2.1586\n","15m 33s (- 14m 1s) (43000 52%) 2.2195\n","15m 55s (- 13m 39s) (44000 53%) 2.1507\n","16m 17s (- 13m 18s) (45000 55%) 2.1527\n","16m 39s (- 12m 56s) (46000 56%) 2.1248\n","17m 1s (- 12m 35s) (47000 57%) 2.1369\n","17m 22s (- 12m 13s) (48000 58%) 2.1611\n","17m 44s (- 11m 51s) (49000 59%) 2.0952\n","18m 6s (- 11m 30s) (50000 61%) 2.1321\n","18m 28s (- 11m 8s) (51000 62%) 2.0877\n","18m 50s (- 10m 46s) (52000 63%) 2.1149\n","19m 13s (- 10m 25s) (53000 64%) 2.1375\n","19m 34s (- 10m 3s) (54000 66%) 2.0870\n","19m 56s (- 9m 42s) (55000 67%) 2.0898\n","20m 18s (- 9m 20s) (56000 68%) 2.0866\n","20m 40s (- 8m 58s) (57000 69%) 2.0791\n","21m 3s (- 8m 37s) (58000 70%) 2.0829\n","21m 25s (- 8m 15s) (59000 72%) 2.0626\n","21m 48s (- 7m 54s) (60000 73%) 2.0464\n","22m 10s (- 7m 32s) (61000 74%) 2.0043\n","Epoch: 3/4\n","22m 32s (- 7m 10s) (62000 75%) 2.0048\n","22m 55s (- 6m 49s) (63000 77%) 1.9938\n","23m 17s (- 6m 27s) (64000 78%) 1.9094\n","23m 39s (- 6m 5s) (65000 79%) 1.9516\n","24m 2s (- 5m 44s) (66000 80%) 1.9800\n","24m 24s (- 5m 22s) (67000 81%) 1.9310\n","24m 46s (- 5m 0s) (68000 83%) 1.9833\n","25m 8s (- 4m 38s) (69000 84%) 1.9462\n","25m 31s (- 4m 16s) (70000 85%) 1.9415\n","25m 53s (- 3m 55s) (71000 86%) 1.9373\n","26m 15s (- 3m 33s) (72000 88%) 1.9522\n","26m 37s (- 3m 11s) (73000 89%) 1.9847\n","26m 59s (- 2m 49s) (74000 90%) 1.9733\n","27m 21s (- 2m 27s) (75000 91%) 1.9311\n","27m 44s (- 2m 5s) (76000 92%) 1.9299\n","28m 7s (- 1m 44s) (77000 94%) 1.9618\n","28m 29s (- 1m 22s) (78000 95%) 1.9293\n","28m 51s (- 1m 0s) (79000 96%) 1.8896\n","29m 14s (- 0m 38s) (80000 97%) 1.9978\n","29m 36s (- 0m 16s) (81000 99%) 1.8744\n"]}],"source":["hidden_size = 256\n","epochs = 4\n","num_layers=4\n","\n","encoder5 = EncoderTransformer(input_lang.n_words, hidden_size, num_layers).to(device)\n","decoder5 = AttnDecoderRNN5(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n","\n","trainIters5(encoder5, decoder5, epochs, print_every=1000,learning_rate=0.005)"]},{"cell_type":"code","execution_count":89,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T01:47:24.499907Z","iopub.status.busy":"2024-02-20T01:47:24.499532Z","iopub.status.idle":"2024-02-20T01:54:54.325271Z","shell.execute_reply":"2024-02-20T01:54:54.324264Z","shell.execute_reply.started":"2024-02-20T01:47:24.499877Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0/1\n","0m 22s (- 7m 10s) (1000 4%) 1.7298\n","0m 44s (- 6m 48s) (2000 9%) 1.7767\n","1m 6s (- 6m 26s) (3000 14%) 1.7092\n","1m 28s (- 6m 2s) (4000 19%) 1.6992\n","1m 50s (- 5m 40s) (5000 24%) 1.6937\n","2m 12s (- 5m 18s) (6000 29%) 1.6963\n","2m 34s (- 4m 55s) (7000 34%) 1.7529\n","2m 56s (- 4m 33s) (8000 39%) 1.6309\n","3m 18s (- 4m 11s) (9000 44%) 1.6501\n","3m 39s (- 3m 49s) (10000 48%) 1.6147\n","4m 1s (- 3m 27s) (11000 53%) 1.6489\n","4m 23s (- 3m 5s) (12000 58%) 1.6674\n","4m 45s (- 2m 43s) (13000 63%) 1.5991\n","5m 7s (- 2m 21s) (14000 68%) 1.5680\n","5m 29s (- 1m 59s) (15000 73%) 1.5977\n","5m 51s (- 1m 37s) (16000 78%) 1.6122\n","6m 13s (- 1m 15s) (17000 83%) 1.5864\n","6m 35s (- 0m 53s) (18000 88%) 1.5508\n","6m 57s (- 0m 31s) (19000 92%) 1.5786\n","7m 20s (- 0m 9s) (20000 97%) 1.4717\n"]}],"source":["#损失下降不明显了，可以调低学习率再跑1个epoch试试\n","trainIters5(encoder5, decoder5, 1, print_every=1000,learning_rate=0.001)"]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T01:59:18.368287Z","iopub.status.busy":"2024-02-20T01:59:18.367517Z","iopub.status.idle":"2024-02-20T02:06:50.886146Z","shell.execute_reply":"2024-02-20T02:06:50.885082Z","shell.execute_reply.started":"2024-02-20T01:59:18.368255Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0/1\n","0m 22s (- 7m 14s) (1000 4%) 1.4623\n","0m 44s (- 6m 50s) (2000 9%) 1.5248\n","1m 7s (- 6m 29s) (3000 14%) 1.4842\n","1m 29s (- 6m 7s) (4000 19%) 1.4657\n","1m 51s (- 5m 44s) (5000 24%) 1.4772\n","2m 13s (- 5m 21s) (6000 29%) 1.4578\n","2m 35s (- 4m 58s) (7000 34%) 1.5347\n","2m 57s (- 4m 36s) (8000 39%) 1.4972\n","3m 20s (- 4m 14s) (9000 44%) 1.5611\n","3m 41s (- 3m 51s) (10000 48%) 1.5113\n","4m 4s (- 3m 29s) (11000 53%) 1.5331\n","4m 26s (- 3m 7s) (12000 58%) 1.5795\n","4m 48s (- 2m 44s) (13000 63%) 1.4698\n","5m 10s (- 2m 22s) (14000 68%) 1.4892\n","5m 32s (- 2m 0s) (15000 73%) 1.5089\n","5m 54s (- 1m 38s) (16000 78%) 1.5077\n","6m 16s (- 1m 16s) (17000 83%) 1.5168\n","6m 38s (- 0m 53s) (18000 88%) 1.4753\n","7m 0s (- 0m 31s) (19000 92%) 1.5004\n","7m 22s (- 0m 9s) (20000 97%) 1.4168\n"]}],"source":["trainIters5(encoder5, decoder5, 1, print_every=1000,learning_rate=0.0005)"]},{"cell_type":"code","execution_count":96,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T02:07:40.980328Z","iopub.status.busy":"2024-02-20T02:07:40.979499Z","iopub.status.idle":"2024-02-20T02:15:22.028037Z","shell.execute_reply":"2024-02-20T02:15:22.026997Z","shell.execute_reply.started":"2024-02-20T02:07:40.980293Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0/1\n","0m 22s (- 7m 22s) (1000 4%) 1.4427\n","0m 45s (- 7m 0s) (2000 9%) 1.4825\n","1m 8s (- 6m 36s) (3000 14%) 1.4589\n","1m 30s (- 6m 11s) (4000 19%) 1.4287\n","1m 52s (- 5m 48s) (5000 24%) 1.4339\n","2m 15s (- 5m 25s) (6000 29%) 1.4167\n","2m 37s (- 5m 1s) (7000 34%) 1.4942\n","2m 59s (- 4m 39s) (8000 39%) 1.4408\n","3m 21s (- 4m 16s) (9000 44%) 1.4929\n","3m 43s (- 3m 53s) (10000 48%) 1.4488\n","4m 6s (- 3m 31s) (11000 53%) 1.4844\n","4m 28s (- 3m 8s) (12000 58%) 1.5326\n","4m 51s (- 2m 46s) (13000 63%) 1.4473\n","5m 13s (- 2m 24s) (14000 68%) 1.4266\n","5m 35s (- 2m 1s) (15000 73%) 1.4573\n","5m 58s (- 1m 39s) (16000 78%) 1.4538\n","6m 21s (- 1m 17s) (17000 83%) 1.4417\n","6m 44s (- 0m 54s) (18000 88%) 1.4004\n","7m 7s (- 0m 32s) (19000 92%) 1.4579\n","7m 30s (- 0m 9s) (20000 97%) 1.3398\n"]}],"source":["trainIters5(encoder5, decoder5, 1, print_every=1000,learning_rate=0.0001)"]},{"cell_type":"code","execution_count":100,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T02:17:03.433193Z","iopub.status.busy":"2024-02-20T02:17:03.432424Z","iopub.status.idle":"2024-02-20T02:24:42.135608Z","shell.execute_reply":"2024-02-20T02:24:42.134815Z","shell.execute_reply.started":"2024-02-20T02:17:03.433162Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0/1\n","0m 22s (- 7m 22s) (1000 4%) 1.4151\n","0m 45s (- 7m 2s) (2000 9%) 1.4718\n","1m 8s (- 6m 39s) (3000 14%) 1.4355\n","1m 31s (- 6m 16s) (4000 19%) 1.4205\n","1m 54s (- 5m 52s) (5000 24%) 1.4381\n","2m 16s (- 5m 28s) (6000 29%) 1.4204\n","2m 38s (- 5m 4s) (7000 34%) 1.4798\n","3m 1s (- 4m 41s) (8000 39%) 1.4386\n","3m 23s (- 4m 18s) (9000 44%) 1.4926\n","3m 45s (- 3m 55s) (10000 48%) 1.4549\n","4m 7s (- 3m 32s) (11000 53%) 1.4613\n","4m 30s (- 3m 10s) (12000 58%) 1.5035\n","4m 52s (- 2m 47s) (13000 63%) 1.4390\n","5m 14s (- 2m 24s) (14000 68%) 1.3936\n","5m 37s (- 2m 2s) (15000 73%) 1.4485\n","5m 59s (- 1m 39s) (16000 78%) 1.4421\n","6m 21s (- 1m 17s) (17000 83%) 1.4317\n","6m 44s (- 0m 54s) (18000 88%) 1.4058\n","7m 6s (- 0m 32s) (19000 92%) 1.4321\n","7m 28s (- 0m 9s) (20000 97%) 1.3334\n"]}],"source":["trainIters5(encoder5, decoder5, 1, print_every=1000,learning_rate=0.0001)"]},{"cell_type":"code","execution_count":104,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T02:42:21.977324Z","iopub.status.busy":"2024-02-20T02:42:21.976596Z","iopub.status.idle":"2024-02-20T02:42:22.056652Z","shell.execute_reply":"2024-02-20T02:42:22.055770Z","shell.execute_reply.started":"2024-02-20T02:42:21.977290Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["> je suis soudainement fatigue .\n","= i m suddenly tired .\n","< i m already tired . <EOS>\n","\n","> il semble s interesser a moi .\n","= he seems interested in me .\n","< he seems to to me . <EOS>\n","\n","> je ne suis pas telepathe .\n","= i m not a psychic .\n","< i m not a . <EOS>\n","\n","> tu es un peu en retard .\n","= you re a little late .\n","< you re a little late . <EOS>\n","\n","> nous sommes une bonne equipe .\n","= we re a good team .\n","< we re a good good . <EOS>\n","\n","> je fais ca pour l avenir de nos enfants .\n","= i m doing this for our kids future .\n","< i m doing this for this this . . <EOS>\n","\n","> vous etes habilles trop chaudement .\n","= you re dressed too warmly .\n","< you re probably too young . <EOS>\n","\n","> ce sont tous les deux de bons professeurs .\n","= they are both good teachers .\n","< they re both good . . <EOS>\n","\n","> nous sommes tous deux catholiques .\n","= we re both catholics .\n","< we re both single . <EOS>\n","\n","> espece de gros porc !\n","= you re such a pig .\n","< you re such a liar . <EOS>\n","\n"]}],"source":["evaluateRandomly5(encoder5, decoder5)"]},{"cell_type":"code","execution_count":102,"metadata":{"execution":{"iopub.execute_input":"2024-02-20T02:24:57.943631Z","iopub.status.busy":"2024-02-20T02:24:57.943264Z","iopub.status.idle":"2024-02-20T02:25:19.267812Z","shell.execute_reply":"2024-02-20T02:25:19.266837Z","shell.execute_reply.started":"2024-02-20T02:24:57.943601Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2271/2271 [00:21<00:00, 107.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["=== Evaluation score - Rouge score ===\n","Rouge1 fmeasure:\t 0.5901358\n","Rouge1 precision:\t 0.56192356\n","Rouge1 recall:  \t 0.6300863\n","Rouge2 fmeasure:\t 0.4014541\n","Rouge2 precision:\t 0.37587482\n","Rouge2 recall:  \t 0.43890423\n","=====================================\n"]}],"source":["input,gt,predict,score = test5(encoder5, decoder5, test_pairs)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30646,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
